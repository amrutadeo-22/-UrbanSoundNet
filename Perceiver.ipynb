{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutadeo-22/-UrbanSoundNet/blob/main/Perceiver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0qnZWbaC6O6",
        "outputId": "a524ee94-8a6d-4c15-b1f4-48c90c13beac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/50: Loss: 1.7091, Accuracy: 38.54%\n",
            "Epoch 2/50: Loss: 1.4546, Accuracy: 48.08%\n",
            "Epoch 3/50: Loss: 1.3468, Accuracy: 52.16%\n",
            "Epoch 4/50: Loss: 1.2708, Accuracy: 54.42%\n",
            "Epoch 5/50: Loss: 1.1995, Accuracy: 57.22%\n",
            "Epoch 6/50: Loss: 1.1483, Accuracy: 59.01%\n",
            "Epoch 7/50: Loss: 1.0866, Accuracy: 61.18%\n",
            "Epoch 8/50: Loss: 1.0358, Accuracy: 62.88%\n",
            "Epoch 9/50: Loss: 0.9902, Accuracy: 64.87%\n",
            "Epoch 10/50: Loss: 0.9442, Accuracy: 66.33%\n",
            "Epoch 11/50: Loss: 0.8967, Accuracy: 68.08%\n",
            "Epoch 12/50: Loss: 0.8545, Accuracy: 69.70%\n",
            "Epoch 13/50: Loss: 0.8041, Accuracy: 71.65%\n",
            "Epoch 14/50: Loss: 0.7538, Accuracy: 73.31%\n",
            "Epoch 15/50: Loss: 0.7187, Accuracy: 74.52%\n",
            "Epoch 16/50: Loss: 0.6647, Accuracy: 76.53%\n",
            "Epoch 17/50: Loss: 0.6121, Accuracy: 78.47%\n",
            "Epoch 18/50: Loss: 0.5707, Accuracy: 79.83%\n",
            "Epoch 19/50: Loss: 0.5242, Accuracy: 81.53%\n",
            "Epoch 20/50: Loss: 0.4752, Accuracy: 83.49%\n",
            "Epoch 21/50: Loss: 0.4371, Accuracy: 84.49%\n",
            "Epoch 22/50: Loss: 0.3945, Accuracy: 86.22%\n",
            "Epoch 23/50: Loss: 0.3694, Accuracy: 86.93%\n",
            "Epoch 24/50: Loss: 0.3296, Accuracy: 88.45%\n",
            "Epoch 25/50: Loss: 0.3010, Accuracy: 89.47%\n",
            "Epoch 26/50: Loss: 0.2688, Accuracy: 90.63%\n",
            "Epoch 27/50: Loss: 0.2426, Accuracy: 91.46%\n",
            "Epoch 28/50: Loss: 0.2164, Accuracy: 92.47%\n",
            "Epoch 29/50: Loss: 0.2029, Accuracy: 93.01%\n",
            "Epoch 30/50: Loss: 0.1890, Accuracy: 93.42%\n",
            "Epoch 31/50: Loss: 0.1696, Accuracy: 94.19%\n",
            "Epoch 32/50: Loss: 0.1496, Accuracy: 94.90%\n",
            "Epoch 33/50: Loss: 0.1537, Accuracy: 94.62%\n",
            "Epoch 34/50: Loss: 0.1400, Accuracy: 95.17%\n",
            "Epoch 35/50: Loss: 0.1390, Accuracy: 95.11%\n",
            "Epoch 36/50: Loss: 0.1147, Accuracy: 96.01%\n",
            "Epoch 37/50: Loss: 0.1113, Accuracy: 96.19%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from einops import repeat, rearrange\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# Perceiver Model\n",
        "class Perceiver(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, latent_dim=256, num_latents=64, depth=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        self.latents = nn.Parameter(torch.randn(1, num_latents, latent_dim))  # Shape: (1, 64, 256)\n",
        "        self.data_proj = nn.Linear(input_dim, latent_dim)\n",
        "\n",
        "        def get_attention(dim_in, dim_out, heads=8, dim_head=32):\n",
        "            inner_dim = heads * dim_head\n",
        "            return nn.Sequential(\n",
        "                nn.Linear(dim_in, inner_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(inner_dim, dim_out),\n",
        "            )\n",
        "\n",
        "        self.cross_attn = get_attention(latent_dim, latent_dim)\n",
        "        self.self_attn = get_attention(latent_dim, latent_dim)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(latent_dim, latent_dim * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim * 2, latent_dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.to_logits = nn.Sequential(\n",
        "            nn.LayerNorm(latent_dim),\n",
        "            nn.Linear(latent_dim, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, *_ = x.shape\n",
        "        x = self.data_proj(x)  # Shape: (b, 768) â†’ (b, 256)\n",
        "        x = repeat(x, \"b d -> b 1 d\")  # Expand to match latents\n",
        "\n",
        "        latents = repeat(self.latents, \"1 n d -> b n d\", b=b)  # Shape: (b, 64, 256)\n",
        "        latents = latents + self.cross_attn(x)  # Ensure shape match\n",
        "\n",
        "        for _ in range(self.depth):\n",
        "            latents = latents + self.self_attn(latents)\n",
        "            latents = latents + self.feed_forward(latents)\n",
        "\n",
        "        return self.to_logits(latents.mean(dim=1))\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_cifar10():\n",
        "    # Hyperparameters\n",
        "    batch_size = 256\n",
        "    lr = 3e-4\n",
        "    epochs = 50\n",
        "    input_size = 32 * 32 * 3  # 3072\n",
        "    num_classes = 10\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(\"./data\", train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.CIFAR10(\"./data\", train=False, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = Perceiver(input_dim=input_size, num_classes=num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "    scaler = GradScaler(enabled=device.type == \"cuda\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct = 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            images = images.flatten(1)  # Flatten images to (batch_size, 3072)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast(device_type=device.type, enabled=device.type == \"cuda\"):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: Loss: {total_loss/len(train_loader):.4f}, \"\n",
        "              f\"Accuracy: {correct / len(train_loader.dataset) * 100:.2f}%\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            images = images.flatten(1)\n",
        "            outputs = model(images)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    print(f\"Test Accuracy: {correct / len(test_loader.dataset) * 100:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_cifar10()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvNR3bcJ3slmUaoCkWQrnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}